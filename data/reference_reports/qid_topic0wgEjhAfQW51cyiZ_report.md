# Do K–12 Standardized Tests Help or Harm Learning and Well-Being? A Source-Linked Review for U.S. Parents

## Executive Summary

- High-stakes testing periods measurably elevate stress and test anxiety for U.S. K–12 students, especially in elementary and middle grades; stronger physiological stress responses correlate with lower test performance on those high-stakes exams (quasi-experimental evidence) [Testing, Stress, and Performance (Education Finance and Policy)](https://direct.mit.edu/edfp/article/16/2/183/97156/Testing-Stress-and-Performance-How-Students) [2]; [NBER Working Paper 25305](https://www.nber.org/papers/w25305) [3]; [Heightened test anxiety among young children (Psychology in the Schools)](https://doi.org/10.1002/pits.21689) [1]; [Meta-analysis on test anxiety and performance](https://www.sciencedirect.com/science/article/abs/pii/S0165032717303683) [6].

- Accountability pressures (especially under NCLB) led to time shifting toward tested ELA/math and away from science, social studies, and arts in elementary grades; effects are strongest where accountability stakes are higher (difference-in-differences and panel studies) [NCLB time reallocation (EEPA)](https://journals.sagepub.com/doi/10.3102/0162373712467080) [14]; [Chicago accountability responses (NBER)](https://www.nber.org/papers/w8968) [15]; [Audit-test divergence under pressure (RSF)](https://www.rsfjournal.org/content/2/5/220) [17].

- SAT/ACT and state assessments moderately predict college performance; combining SAT/ACT with high school GPA improves prediction in most contexts. State tests like SBAC and PARCC/MCAS predict first-year GPA comparably to SAT in studied systems; high school GPA is often the single strongest predictor at broad-access publics (observational, multi-institution) [College Board SAT Validity Hub](https://research.collegeboard.org/reports/sat-suite/validity) [21]; [ACT Research Brief R2419 (2025)](https://www.act.org/content/act/en/research/pdfs/R2419-Validity-ACT-Composite-Score-HSGPA-2025-02.html) [25]; [PACE study—SBAC vs SAT vs HSGPA](https://edpolicyinca.org/sites/default/files/R_Kurlaender_Mar-2019.pdf) [27]; [Mathematica: PARCC vs. MCAS](https://www.mathematica.org/news/parcc-and-mcas-exams-comparable-in-predicting-college-outcomes) [28]; [Berry & Sackett on course grades (Psych Science)](https://journals.sagepub.com/doi/10.1111/j.1467-9280.2009.02368.x) [24].

- Test-optional impacts are mixed: a quasi-experimental study at a highly selective college found test-optional reduced the admission chances of some high-achieving disadvantaged students who withheld strong scores; scores added predictive information for all income groups (quasi-experimental) [NBER Working Paper 33389 (Dartmouth)](https://www.nber.org/papers/w33389) [34]; [NBER Digest summary](https://www.nber.org/digest/202504/test-optional-policies-and-disadvantaged-students) [35]. Some selective universities reinstated test requirements citing predictive value and equity in identifying talent [Reuters: Yale reinstates testing](https://www.reuters.com/world/us/yale-university-reinstates-standardized-test-requirement-2024-02-22/) [38]. The University of California’s test-free era coincided with record resident and underrepresented admits and stable retention (descriptive) [UC press: record admits—URM surge](https://www.universityofcalifornia.edu/press-room/university-california-breaks-admissions-records-surges-california-and-underrepresented) [36]; [UC press: record California residents](https://www.universityofcalifornia.edu/press-room/university-california-admits-record-number-california-residents-and-largest-class) [37].

- Credible alternatives exist (performance-based assessments, portfolios, competency-based systems). New Hampshire’s PACE pilot produced “no harm” to slight positive achievement effects and earned federal IADA approval (peer-reviewed and federal evaluation); NYC’s Performance Standards Consortium shows positive college outcomes for PBAT graduates in a CUNY pilot; multi-state “deeper learning” networks increased graduation and college-going (independent evaluations) [NH PACE (NH DOE)](https://www.education.nh.gov/who-we-are/division-of-learner-support/bureau-of-instructional-support/performance-assessment-competency-education) [41]; [PACE impact (EPAA)](https://epaa.asu.edu/index.php/epaa/article/view/4014) [43]; [IADA evaluation (IES)](https://ies.ed.gov/ncee/pubs/2023004/pdf/2023004.pdf) [45]; [NY Performance Standards Consortium](https://www.performanceassessment.org/howitworks) [46]; [LPI CUNY–Consortium outcomes](https://learningpolicyinstitute.org/product/assessing-college-readiness-authentic-student-work-report) [47]; [AIR Deeper Learning project](https://www.air.org/project/study-deeper-learning-opportunities-and-outcomes) [56]; [AIR graduation advantage](https://www.air.org/news/press-release/air-study-finds-persistent-graduation-advantage-students-deeper-learning-network) [57].

Strength of evidence: Stress/anxiety effects—moderate to strong (quasi-experimental + meta-analysis). Curriculum narrowing—moderate to strong (DiD/panel + national surveys). Predictive validity—moderate (observational, multi-institution; some quasi-experimental for policy edges). Alternatives—moderate (peer-reviewed plus federal evaluation; scaling challenges documented). Equity implications—moderate (test score income gradients descriptive; subgroup differential prediction mostly small in validity studies; policy calibration matters) [Opportunity Insights: test score gradients](https://opportunityinsights.org/paper/test-scores/) [33]; [College Board SAT Validity Hub](https://research.collegeboard.org/reports/sat-suite/validity) [21].

---

## Definitions and Scope

- Standardized tests covered: state accountability assessments (e.g., SBAC, PARCC/MCAS), district interim/benchmark tests, nationally normed assessments (e.g., MAP), and college entrance exams (SAT/ACT) [CGCS district testing inventory](http://www.cgcs.org/cms/lib/DC00001581/Centricity/Domain/87/Testing%20Report.pdf) [10]; [CAP Testing Overload](https://www.americanprogress.org/article/testing-overload-in-americas-schools/) [11].

- Stakes:
  - High-stakes (HS): consequences for schools/educators and sometimes students (e.g., promotion/graduation).
  - Low-stakes (LS): minimal direct student consequences (e.g., annual state tests used for accountability).
  - Interim/benchmark (INT): periodic district exams to monitor progress [CGCS inventory](http://www.cgcs.org/cms/lib/DC00001581/Centricity/Domain/87/Testing%20Report.pdf) [10].

- Outcomes of interest: student stress/anxiety/motivation, instructional time/curriculum/pedagogy, predictive validity for college and career, and credible assessment alternatives.

---

## 1) Student Well-Being and Motivation

### What the evidence says

- Elementary students report higher total, cognitive, and physiological test anxiety for state accountability tests than for classroom tests, using validated scales (e.g., CTAS); effect sizes roughly r ≈ .10–.24 (correlational) [Heightened test anxiety among young children (Psychology in the Schools)](https://doi.org/10.1002/pits.21689) [1].

- Physiological stress rises on high-stakes testing days: salivary cortisol was 15–18% higher during test weeks in grades 3–8 in a low-income network, and students with the largest stress reactivity scored ≈0.40 SD below expected on the high-stakes exam (within-student comparisons; quasi-experimental) [Testing, Stress, and Performance (Education Finance and Policy)](https://direct.mit.edu/edfp/article/16/2/183/97156/Testing-Stress-and-Performance-How-Students) [2]; [NBER Working Paper 25305](https://www.nber.org/papers/w25305) [3].

- The anxiety–performance link is strongest in middle grades (meta-analysis spanning K–12 and higher education; correlational) [Meta-analysis on test anxiety and performance](https://www.sciencedirect.com/science/article/abs/pii/S0165032717303683) [6].

- In 11th grade, total test anxiety predicts lower performance on a statewide exam even after controlling for GPA (correlational) [Statewide exam and test anxiety (FRIEDBEN) study](https://www.tandfonline.com/doi/full/10.1080/15377903.2014.888529) [8].

- On-test engagement is high on low-stakes state exams but declines by grade: response-time-effort analyses show more disengagement in grade 8 than grade 3, with subgroup differences (correlational) [Response Time Effort on a large U.S. state assessment](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2023.1127644/full) [4].

- Absences closer to test dates are associated with larger score losses than earlier-year absences, showing sensitivity of results to testing-window conditions (correlational) [Absence timing and achievement (Educational Researcher)](https://journals.sagepub.com/doi/full/10.3102/0013189X17703945) [7].

- Students with learning disabilities report higher test anxiety on worry and cognitive obstruction factors than peers (correlational) [TAICA differences for LD vs non-LD](https://journals.sagepub.com/doi/10.1177/00222194070400040601) [9].

- Perceptions of testing load vary: a 2016 Gallup–NWEA survey found most students in grades 5–12 said testing time was “about right” or “too little,” while most principals and superintendents said “too much” (perceptions) [Gallup–NWEA Assessment Work](https://www.gallup.com/services/191261/assessment-work-students-multiple-measures-matter.aspx) [13].

### Heterogeneity and subgroups

- Stress reactivity gender differences were observed in the cortisol study, with boys showing larger pretest increases during HS testing weeks (quasi-experimental) [Testing, Stress, and Performance (Education Finance and Policy)](https://direct.mit.edu/edfp/article/16/2/183/97156/Testing-Stress-and-Performance-How-Students) [2]; [NBER Working Paper 25305](https://www.nber.org/papers/w25305) [3].

- Socioeconomic context matters: the physiological study covered a low-income sample; external validity to more advantaged contexts is uncertain (study limitation) [Testing, Stress, and Performance (Education Finance and Policy)](https://direct.mit.edu/edfp/article/16/2/183/97156/Testing-Stress-and-Performance-How-Students) [2].

- Qualitative work in a high-poverty elementary school shows students link testing to adult stakes and self-concept, potentially affecting motivation (qualitative) [Third graders’ experiences with high-stakes testing](https://www.tandfonline.com/doi/full/10.1111/j.1467-873X.2012.00597.x) [5].

### Interim/benchmark and nationally normed tests

- U.S. large-district inventories show many tests are district-mandated (including K–2) and that students take multiple standardized assessments annually (descriptive) [CGCS testing inventory](http://www.cgcs.org/cms/lib/DC00001581/Centricity/Domain/87/Testing%20Report.pdf) [10]; [CAP Testing Overload](https://www.americanprogress.org/article/testing-overload-in-americas-schools/) [11]. Direct causal evidence linking interim/benchmark frequency to student mental health is limited (evidence gap).

### Limitations and strength

- Most stress/anxiety evidence is correlational; however, physiological within-student designs strengthen causal claims that high-stakes testing days raise stress and that reactivity relates to lower performance (moderate–strong evidence) [Testing, Stress, and Performance (Education Finance and Policy)](https://direct.mit.edu/edfp/article/16/2/183/97156/Testing-Stress-and-Performance-How-Students) [2]; [Meta-analysis on anxiety](https://www.sciencedirect.com/science/article/abs/pii/S0165032717303683) [6].

---

## 2) Teaching and Curriculum

### Testing volume and time burden

- In 66 large U.S. districts, students encountered an average of 112 required standardized tests from pre-K through grade 12, with average testing time around 4.2 days in grade 8; many tests were district-level rather than state-required (descriptive) [Student Testing in America’s Great City Schools (CGCS)](http://www.cgcs.org/cms/lib/DC00001581/Centricity/Domain/87/Testing%20Report.pdf) [10].

- A national scan concluded students in grades 3–8 averaged ~10 standardized assessments yearly, with districts often adding interim tests; K–2 testing was largely district-driven (descriptive) [Testing Overload in America’s Schools (CAP)](https://www.americanprogress.org/article/testing-overload-in-americas-schools/) [11].

- The U.S. Department of Education’s 2015 Testing Action Plan recommended states/districts aim for ≤2% of instructional time for statewide standardized testing (policy guidance) [ED Testing Action Plan fact sheet](https://www.legistorm.com/stormfeed/view_rss/834549/organization/69539/title/fact-sheet-testing-action-plan.html) [12].

### Curriculum narrowing and instructional time shifts

- NCLB shifted time away from science and social studies toward reading, especially in elementary grades; overall core time remained similar, implying reallocation rather than expansion (difference-in-differences) [NCLB time reallocation (EEPA)](https://journals.sagepub.com/doi/10.3102/0162373712467080) [14].

- Under school accountability (Chicago), teachers substituted away from low-stakes subjects (science/social studies) and used strategies like retention/special education referrals; gains concentrated on tested outcomes (student-level panel) [Chicago accountability responses (NBER)](https://www.nber.org/papers/w8968) [15].

### Teaching to the test and pedagogy

- Schools under strong accountability pressure intensified test-focused efforts: New York City schools receiving low accountability grades made immediate test score gains, consistent with rapid shifts in instructional priorities (regression discontinuity) [NYC accountability grades (AEJ Policy)](https://ideas.repec.org/a/aea/aejpol/v2y2010i4p119-47.html) [16].

- Gains on high-stakes tests often outpaced gains on lower-stakes “audit” assessments, consistent with alignment to tested formats/skills over broader learning (panel evidence) [High-stakes vs. audit-test divergence (RSF)](https://www.rsfjournal.org/content/2/5/220) [17].

- Interim/benchmark testing does not produce broad gains on average: a large RCT of interim assessments found null average effects in grades 3–8 and negative effects in K–2, with benefits concentrated among lower achievers (quantile effects) [Interim assessments RCT](https://www.tandfonline.com/doi/full/10.1080/19345747.2015.1116031) [18].

- In the Common Core era, teachers reported shifting practices and heavy use of self-curated materials, often of varying alignment quality (surveys) [RAND Common Core implementation](https://www.rand.org/pubs/research_reports/RR2658.html) [19].

### Ethical pressure indicators

- Statistical detection and retest verification in Chicago estimated 4–5% of elementary classrooms engaged in serious test manipulation under high-stakes incentives (causal detection design) [Teacher cheating detection (NBER)](https://www.nber.org/papers/w9413) [20].

### Heterogeneity and context

- The largest curriculum/time shifts appeared in elementary grades and in schools facing improvement sanctions; subject-specific stakes (e.g., testing social studies) increase time in that subject (multiple studies; see above) [NCLB time reallocation (EEPA)](https://journals.sagepub.com/doi/10.3102/0162373712467080) [14]; [Chicago accountability (NBER)](https://www.nber.org/papers/w8968) [15].

### Strength and limitations

- The time/curriculum literature includes multiple causal designs (DiD, RDD, RCT) and converges with large-scale descriptive surveys; evidence strength is moderate-to-strong overall [NCLB time reallocation (EEPA)](https://journals.sagepub.com/doi/10.3102/0162373712467080) [14]; [NYC RDD](https://ideas.repec.org/a/aea/aejpol/v2y2010i4p119-47.html) [16]; [Audit-test divergence (RSF)](https://www.rsfjournal.org/content/2/5/220) [17]; [Interim assessments RCT](https://www.tandfonline.com/doi/full/10.1080/19345747.2015.1116031) [18].

---

## 3) Predictive Validity and Long-Term Outcomes

### SAT/ACT: college performance and persistence

- Across hundreds of thousands of students, SAT scores predict first-year college GPA (FYGPA), and combining SAT with high school GPA improves prediction over GPA alone; validity generally holds across examined subgroups (observational, adjusted for range restriction) [SAT Validity (College Board Research Hub)](https://research.collegeboard.org/reports/sat-suite/validity) [21].

- College Board reports that the digital SAT shows similar or larger incremental validity gains over HSGPA (policy/technical brief) [Predictive validity, digital SAT (College Board)](https://international.collegeboard.org/toolkit/sat-policy/understanding-sat/predictive-validity) [22]; [Digital SAT pilot validity study](https://www.researchgate.net/publication/375765549_Digital_SAT_R_Pilot_Predictive_Validity_Study_-A_Comprehensive_Analysis_of_First-Year_College_Outcomes) [23].

- ACT Composite and HSGPA are both strong predictors of FYGPA and credit accumulation; adding ACT helps address declines in the predictive power of HSGPA linked to grade inflation (observational, multi-institution) [ACT Research Brief R2419 (2025)](https://www.act.org/content/act/en/research/pdfs/R2419-Validity-ACT-Composite-Score-HSGPA-2025-02.html) [25]; [Meta-analysis (ACT/HSGPA/SES)](https://www.researchgate.net/publication/273897715_College_Performance_and_Retention_A_Meta-Analysis_of_the_Predictive_Validities_of_ACT_R_Scores_High_School_Grades_and_SES) [26].

- Using course-grade criteria, SAT + HSGPA explained 44–62% of variance in individual course grades (large-sample observational) [Berry & Sackett (Psych Science)](https://journals.sagepub.com/doi/10.1111/j.1467-9280.2009.02368.x) [24].

### State accountability tests predicting college outcomes

- In California, SBAC predicted FYGPA and second-year persistence as well as SAT; HSGPA was often the strongest predictor at CSU; using HSGPA + SBAC yielded more diverse top candidates than HSGPA + SAT (observational, CSU/UC cohorts) [PACE report: SBAC vs SAT vs HSGPA](https://edpolicyinca.org/sites/default/files/R_Kurlaender_Mar-2019.pdf) [27].

- In Massachusetts, PARCC and MCAS were comparable in predicting college outcomes; PARCC’s “college-ready” cut aligned more closely with B-average performance and lower remediation than MCAS “proficient,” highlighting the importance of standard-setting (observational) [Mathematica: PARCC vs. MCAS (news)](https://www.mathematica.org/news/parcc-and-mcas-exams-comparable-in-predicting-college-outcomes) [28]; [Mathematica In Focus](https://www.mathematica.org/publications/in-focus-for-massachusetts-students-parcc-and-mcas-exams-comparable-in-predicting-college-outcomes) [29].

### Exit exams and causal long-run effects

- Regression discontinuity around the MCAS pass/fail threshold shows that barely passing increases on-time graduation (≈+3 percentage points for low-income students) and, for higher-income students, modestly increases four-year enrollment and graduation (causal) [Annenberg/Brown MCAS RDD report](https://annenberg.brown.edu/sites/default/files/Annenberg%20-%20MCAS%20as%20a%20Graduation%20Requirement_1.pdf) [30].

### Careers and job performance (context)

- General cognitive/achievement test performance is a moderate predictor of job performance and training success in the labor market (meta-analytic synthesis; not SAT-specific) [Meta-analysis of GCA–job performance (PubMed)](https://pubmed.ncbi.nlm.nih.gov/38059952/) [31]; [Selection validity overview (Cambridge IOP)](https://www.cambridge.org/core/journals/industrial-and-organizational-psychology/article/revisiting-the-design-of-selection-systems-in-light-of-new-findings-regarding-the-validity-of-widely-used-predictors/A20984B138319E3D432E643978BF026D) [32].

### Equity and score gradients

- Test scores are strongly stratified by household income in U.S. data, reflecting upstream opportunity differences (descriptive) [Opportunity Insights: test scores](https://opportunityinsights.org/paper/test-scores/) [33].

- Validity studies typically find similar predictive relationships across subgroups for SAT/ACT, though average score gaps by income/race persist (observational) [SAT Validity (College Board)](https://research.collegeboard.org/reports/sat-suite/validity) [21]; [ACT Research Brief R2419](https://www.act.org/content/act/en/research/pdfs/R2419-Validity-ACT-Composite-Score-HSGPA-2025-02.html) [25].

### Test-optional/test-free admissions

- At a highly selective college, test-optional reduced admission odds for many high-scoring disadvantaged students who withheld scores; score-reporting increased admission odds 2.4–3.6x for otherwise similar high-scorers; FYGPA prediction from tests was similar across income groups (quasi-experimental) [NBER Working Paper 33389 (Dartmouth)](https://www.nber.org/papers/w33389) [34]; [NBER Digest](https://www.nber.org/digest/202504/test-optional-policies-and-disadvantaged-students) [35].

- Several selective institutions (e.g., Yale) reinstated test requirements, citing predictive value and equity in identifying talent from less-resourced schools (institutional policy rationale) [Reuters report](https://www.reuters.com/world/us/yale-university-reinstates-standardized-test-requirement-2024-02-22/) [38].

- The University of California’s test-free policy era saw record admissions of California residents and underrepresented students and public reporting of strong retention; these are descriptive trends, not causal estimates [UC: URM surge](https://www.universityofcalifornia.edu/press-room/university-california-breaks-admissions-records-surges-california-and-underrepresented) [36]; [UC: record residents](https://www.universityofcalifornia.edu/press-room/university-california-admits-record-number-california-residents-and-largest-class) [37].

### Scholarships and access

- Some state merit aid still requires SAT/ACT thresholds (e.g., Georgia’s Zell Miller Scholarship requires minimum GPA plus a test score; ACT equivalence is updated by concordance) [Georgia Student Finance Commission](https://gsfc.georgia.gov/about-gsfc/georgias-scholarship-grant-and-loan-programs) [39]; [Georgia Southern HOPE/Zell Miller info](https://www.georgiasouthern.edu/admissions-aid/tuition-and-scholarships/types-of-aid/hope-zell-miller-scholarship) [40].

### Strength and limitations

- Predictive validity evidence is largely observational (moderate strength) with consistent multi-institution replication; causal evidence exists for particular policy thresholds (e.g., exit exams) and for test-optional effects at selective colleges (moderate strength) [SAT Validity](https://research.collegeboard.org/reports/sat-suite/validity) [21]; [MCAS RDD](https://annenberg.brown.edu/sites/default/files/Annenberg%20-%20MCAS%20as%20a%20Graduation%20Requirement_1.pdf) [30]; [NBER 33389](https://www.nber.org/papers/w33389) [34].

---

## 4) Alternatives and Case Studies

### New Hampshire’s PACE (Performance Assessment of Competency Education)

- Design: State-led pilot integrating locally developed performance assessments with a small number of common calibration tasks and reduced statewide testing in non-audit grades; aligned to state standards [NH DOE PACE page](https://www.education.nh.gov/who-we-are/division-of-learner-support/bureau-of-instructional-support/performance-assessment-competency-education) [41].

- Federal alignment: Approved under ESSA’s Innovative Assessment Demonstration Authority (IADA) to pilot and scale innovative assessments [NH DOE IADA approval news](https://www.education.nh.gov/news/pace-assessment-approved-feds) [42].

- Outcomes: Peer-reviewed evaluations show small positive impacts in some grades (e.g., grade 8 ELA/math; positive effects for lower achievers) over the first three years, and “no-harm” average results by year five (observational with matched comparisons) [PACE impact (EPAA)](https://epaa.asu.edu/index.php/epaa/article/view/4014) [43]; [Applied Measurement in Education 5-year results](https://www.tandfonline.com/doi/abs/10.1080/08957347.2023.2201700) [44].

- Technical quality and scaling: IES/NCEE’s IADA evaluation documents comparability strategies (common tasks, moderation), cost/logistics demands, and COVID-related scale-up challenges [IADA evaluation (IES)](https://ies.ed.gov/ncee/pubs/2023004/pdf/2023004.pdf) [45].

### New York Performance Standards Consortium (PBATs/portfolios)

- Design: 38 public high schools use Performance-Based Assessment Tasks (PBATs) in lieu of most Regents exams; tasks include literary analysis, social studies research, science investigations, and math problem-solving with oral defenses [NYPSC: How it works](https://www.performanceassessment.org/howitworks) [46].

- Outcomes: In a CUNY admissions pilot, Consortium graduates—including those admitted with PBAT portfolios despite lower SATs—had higher first-semester GPAs, earned more initial credits, and persisted at higher rates than NYC peers (observational) [Learning Policy Institute report](https://learningpolicyinstitute.org/product/assessing-college-readiness-authentic-student-work-report) [47].

- Logistics: Common rubrics, external scoring, and cross-school moderation support reliability and comparability [NYPSC: How it works](https://www.performanceassessment.org/howitworks) [46].

### MCIEA (Massachusetts Consortium for Innovative Education Assessment)

- Design: District–union consortium building a multiple-measures accountability system with teacher-created performance assessments and a School Quality Measures (SQM) dashboard across 34 indicators [MCIEA overview](https://www.mciea.org/) [48].

- Implementation: Year-long Performance Assessment Institute (free PD, 24 PDPs), cross-district scoring and calibration, and technical work on SQM survey reliability [Performance Assessment Institute](https://www.mciea.org/institute) [49]; [SQM research](https://www.mciea.org/school-quality-measures-research) [50].

### Vermont Portfolio Assessment (1990s foundational case)

- Lessons: Early statewide portfolio scoring faced low reliability (e.g., writing reliability ~0.28–0.57; math agreement ~60%), underscoring the need for intense rater training, clearer rubrics, and moderation in large-scale performance assessment [RAND analysis (reprint)](https://www.rand.org/pubs/reprints/RP366.html) [51]; [RAND reliability study (DRU159)](https://www.rand.org/pubs/drafts/DRU159.html) [52].

### Rhode Island Proficiency-Based Graduation Requirements (PBGR)

- Policy: Statewide diploma policy requiring demonstration of proficiency across core areas via multiple measures, including locally designed performance-based assessments (projects, capstones, portfolios) [RIDE PBGR page](https://ride.ri.gov/students-families/education-programs/proficiency-based-learning) [53].

### Envision Schools and Deeper Learning networks

- Envision’s “defense of learning”: Graduation-aligned portfolio defenses with panels; Envision Learning Partners supports districts with PD; concrete logistics/costs shown via Defense Design Studios (e.g., ~$175/participant observation/coaching) [Envision approach](https://envisionschools.org/our-approach/) [54]; [Defense Design Studios](https://envisionschools.org/defense-design-studios/) [55].

- Outcomes: AIR’s multi-state study of deeper learning network high schools (including performance-assessment-rich models) found higher on-time graduation, better test performance, and higher college enrollment vs. matched peers (independent evaluation) [AIR Deeper Learning project](https://www.air.org/project/study-deeper-learning-opportunities-and-outcomes) [56]; [AIR graduation advantage](https://www.air.org/news/press-release/air-study-finds-persistent-graduation-advantage-students-deeper-learning-network) [57].

### International Baccalaureate (IB) Diploma Programme components (U.S. implementations)

- Design: Internal assessments moderated by IB and the Extended Essay (4,000-word research project) alongside external exams; widely implemented in U.S. districts [Understanding IB assessment (DP)](https://www.ibo.org/en/programmes/diploma-programme/assessment-and-exams/understanding-ib-assessment/) [58]; [Extended Essay overview](https://www.ibo.org/programmes/diploma-programme/curriculum/dp-core/extended-essay/what-is-the-extended-essay/) [59].

- Outcomes: U.S. DP students show higher immediate college enrollment, persistence, and degree completion than national averages; district studies (e.g., Chicago) report positive postsecondary effects (synthesized by IB) [IB U.S. postsecondary outcomes](https://www.ibo.org/research/outcomes-research/diploma-studies/us-postsecondary-outcomes/) [60].

### Pennsylvania Project Based Assessments (PBAs) as Keystone alternatives

- Policy/design: Under Act 158, students can meet graduation pathways using state-provided or locally designed Project Based Assessments aligned to Keystone content standards; PDE provides PBA modules in Algebra I, Biology, and Literature [PDE PBA portal](https://www.pba.pdesas.org/assessment/assessment/projectbasedassessment/) [61]; [Keystone Exams overview](https://www.education.pa.gov/K-12/Assessment%20and%20Accountability/Keystones/Pages/default.aspx) [62].

### Cross-cutting lessons on design, cost, and scalability

- Comparability can be supported via common tasks, anchor papers, external moderation, and technical audits (PACE, NYPSC, IB), but this requires sustained investment and capacity [NH DOE PACE](https://www.education.nh.gov/who-we-are/division-of-learner-support/bureau-of-instructional-support/performance-assessment-competency-education) [41]; [IADA evaluation (IES)](https://ies.ed.gov/ncee/pubs/2023004/pdf/2023004.pdf) [45]; [NYPSC: How it works](https://www.performanceassessment.org/howitworks) [46]; [IB assessment](https://www.ibo.org/en/programmes/diploma-programme/assessment-and-exams/understanding-ib-assessment/) [58].

- Early statewide portfolio attempts without strong moderation (Vermont) struggled with reliability, a caution for scaling [RAND Vermont analyses](https://www.rand.org/pubs/reprints/RP366.html) [51]; [DRU159](https://www.rand.org/pubs/drafts/DRU159.html) [52].

---

## 5) Practical Guidance for Parents

- Likely benefits:
  - When tests are used as one part of a multiple-measures system and aligned to standards that emphasize reasoning and writing, they can inform instruction and predict near-term success, especially when combined with GPA [SAT Validity (College Board)](https://research.collegeboard.org/reports/sat-suite/validity) [21]; [PACE impact evaluations](https://epaa.asu.edu/index.php/epaa/article/view/4014) [43]; [AIR deeper learning outcomes](https://www.air.org/project/study-deeper-learning-opportunities-and-outcomes) [56].

- Likely harms/tradeoffs:
  - High-stakes testing weeks elevate stress and anxiety and can prompt curriculum narrowing and test-focused pedagogy, particularly in elementary grades and high-pressure contexts [EFP cortisol study](https://direct.mit.edu/edfp/article/16/2/183/97156/Testing-Stress-and-Performance-How-Students) [2]; [NCLB time shifts](https://journals.sagepub.com/doi/10.3102/0162373712467080) [14]; [Audit-test divergence](https://www.rsfjournal.org/content/2/5/220) [17].

- Questions to ask your school/district:
  - What proportion of assessments are state-required versus district-added? What is the total annual testing time by grade? [CGCS testing inventory](http://www.cgcs.org/cms/lib/DC00001581/Centricity/Domain/87/Testing%20Report.pdf) [10].
  - How are interim assessments used (diagnosis/feedback vs. prediction/practice)? What evidence supports their benefit for your students? [Interim assessments RCT](https://www.tandfonline.com/doi/full/10.1080/19345747.2015.1116031) [18].
  - What performance-based assessments, capstones, or portfolios are used to demonstrate competencies? How is scoring moderated to ensure fairness and comparability? [NH PACE](https://www.education.nh.gov/who-we-are/division-of-learner-support/bureau-of-instructional-support/performance-assessment-competency-education) [41]; [NYPSC](https://www.performanceassessment.org/howitworks) [46].

- Mitigating student stress:
  - Ask for transparent testing calendars and supports (e.g., practice with item types, not just test drills), attention to test-day logistics (sleep, breakfast, scheduling), and access to accommodations if eligible [EFP cortisol study](https://direct.mit.edu/edfp/article/16/2/183/97156/Testing-Stress-and-Performance-How-Students) [2]; [ACT accommodations and supports—see ACT research briefs for context on score relationships] (context for accommodations not separately cited here).

---

## Uncertainties and Research Gaps

- Intrinsic motivation: Direct, causal U.S. K–12 evidence tying accountability testing to validated intrinsic motivation scales is limited relative to anxiety/stress studies (gap).

- Interim/benchmark testing and well-being: While testing volume is well documented, causal evidence linking interim frequency to student mental health is scarce (gap) [CGCS testing inventory](http://www.cgcs.org/cms/lib/DC00001581/Centricity/Domain/87/Testing%20Report.pdf) [10]; [CAP Testing Overload](https://www.americanprogress.org/article/testing-overload-in-americas-schools/) [11].

- Equity calibration: More work is needed on subgroup calibration for state tests (e.g., English learners) and on guidance to ensure test-optional policies do not unintentionally disadvantage high-achieving low-income students [MCAS RDD synthesis](https://annenberg.brown.edu/sites/default/files/Annenberg%20-%20MCAS%20as%20a%20Graduation%20Requirement_1.pdf) [30]; [NBER 33389](https://www.nber.org/papers/w33389) [34].

---

### Sources

[1] Heightened test anxiety among young children (Psychology in the Schools): https://doi.org/10.1002/pits.21689  
[2] Testing, Stress, and Performance—How Students Respond Physiologically to High-Stakes Testing (Education Finance and Policy): https://direct.mit.edu/edfp/article/16/2/183/97156/Testing-Stress-and-Performance-How-Students  
[3] High-Stakes, Examinations, Stress, and Achievement (NBER Working Paper 25305): https://www.nber.org/papers/w25305  
[4] How engaged are students in low-stakes tests? Response Time Effort in a large U.S. state assessment (Frontiers in Education): https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2023.1127644/full  
[5] Third graders’ experiences with high-stakes testing (Qualitative Study, Taylor & Francis): https://www.tandfonline.com/doi/full/10.1111/j.1467-873X.2012.00597.x  
[6] The relation between test anxiety and academic performance: A meta-analysis (ScienceDirect): https://www.sciencedirect.com/science/article/abs/pii/S0165032717303683  
[7] Absence and achievement: A study of timing (Educational Researcher): https://journals.sagepub.com/doi/full/10.3102/0013189X17703945  
[8] Test anxiety and high-stakes performance in 11th grade (Taylor & Francis): https://www.tandfonline.com/doi/full/10.1080/15377903.2014.888529  
[9] Test anxiety differences for students with learning disabilities (Journal of Learning Disabilities, SAGE): https://journals.sagepub.com/doi/10.1177/00222194070400040601  
[10] Student Testing in America’s Great City Schools (CGCS): http://www.cgcs.org/cms/lib/DC00001581/Centricity/Domain/87/Testing%20Report.pdf  
[11] Testing Overload in America’s Schools (Center for American Progress): https://www.americanprogress.org/article/testing-overload-in-americas-schools/  
[12] Fact Sheet: Testing Action Plan (U.S. Department of Education via LegiStorm): https://www.legistorm.com/stormfeed/view_rss/834549/organization/69539/title/fact-sheet-testing-action-plan.html  
[13] Assessment Work: Students and Multiple Measures Matter (Gallup–NWEA): https://www.gallup.com/services/191261/assessment-work-students-multiple-measures-matter.aspx  
[14] The impact of No Child Left Behind on teachers’ time (Educational Evaluation and Policy Analysis): https://journals.sagepub.com/doi/10.3102/0162373712467080  
[15] Accountability, incentives, and behavior: Evidence from Chicago (NBER Working Paper 8968): https://www.nber.org/papers/w8968  
[16] Information and employee evaluation: Evidence from NYC schools (AEJ: Policy, link via IDEAS): https://ideas.repec.org/a/aea/aejpol/v2y2010i4p119-47.html  
[17] The educational consequences of test-based accountability (RSF Journal): https://www.rsfjournal.org/content/2/5/220  
[18] Does interim assessment improve achievement? Evidence from a large-scale RCT (Taylor & Francis): https://www.tandfonline.com/doi/full/10.1080/19345747.2015.1116031  
[19] What teachers know and do in the Common Core era (RAND RR2658): https://www.rand.org/pubs/research_reports/RR2658.html  
[20] Rotten apples: An investigation of the prevalence and predictors of test cheating (NBER Working Paper 9413): https://www.nber.org/papers/w9413  
[21] SAT Validity—College Board Research Hub: https://research.collegeboard.org/reports/sat-suite/validity  
[22] Understanding SAT predictive validity (College Board International): https://international.collegeboard.org/toolkit/sat-policy/understanding-sat/predictive-validity  
[23] Digital SAT Pilot Predictive Validity Study: https://www.researchgate.net/publication/375765549_Digital_SAT_R_Pilot_Predictive_Validity_Study_-A_Comprehensive_Analysis_of_First-Year_College_Outcomes  
[24] The validity of the SAT for predicting course grades (Psychological Science): https://journals.sagepub.com/doi/10.1111/j.1467-9280.2009.02368.x  
[25] Validity of ACT Composite and HSGPA for predicting CGPA and hours earned (ACT Research Brief R2419, 2025): https://www.act.org/content/act/en/research/pdfs/R2419-Validity-ACT-Composite-Score-HSGPA-2025-02.html  
[26] College Performance and Retention: A Meta-Analysis of ACT, HSGPA, SES (ResearchGate): https://www.researchgate.net/publication/273897715_College_Performance_and_Retention_A_Meta-Analysis_of_the_Predictive_Validities_of_ACT_R_Scores_High_School_Grades_and_SES  
[27] Gauging college readiness: SBAC vs SAT vs HSGPA at CSU/UC (PACE): https://edpolicyinca.org/sites/default/files/R_Kurlaender_Mar-2019.pdf  
[28] PARCC and MCAS comparable in predicting college outcomes (Mathematica news): https://www.mathematica.org/news/parcc-and-mcas-exams-comparable-in-predicting-college-outcomes  
[29] In Focus: PARCC and MCAS comparability (Mathematica): https://www.mathematica.org/publications/in-focus-for-massachusetts-students-parcc-and-mcas-exams-comparable-in-predicting-college-outcomes  
[30] MCAS as a Graduation Requirement—Causal impacts (Annenberg/Brown): https://annenberg.brown.edu/sites/default/files/Annenberg%20-%20MCAS%20as%20a%20Graduation%20Requirement_1.pdf  
[31] Meta-analysis: General mental ability and job performance (PubMed): https://pubmed.ncbi.nlm.nih.gov/38059952/  
[32] Revisiting selection validity (Industrial and Organizational Psychology, Cambridge): https://www.cambridge.org/core/journals/industrial-and-organizational-psychology/article/revisiting-the-design-of-selection-systems-in-light-of-new-findings-regarding-the-validity-of-widely-used-predictors/A20984B138319E3D432E643978BF026D  
[33] Opportunity Insights—Test scores and access: https://opportunityinsights.org/paper/test-scores/  
[34] Test-Optional Policies and Disadvantaged Students (NBER Working Paper 33389): https://www.nber.org/papers/w33389  
[35] NBER Digest: Test-optional and disadvantaged students (2025): https://www.nber.org/digest/202504/test-optional-policies-and-disadvantaged-students  
[36] UC press: Admissions records—surges in CA and underrepresented students: https://www.universityofcalifornia.edu/press-room/university-california-breaks-admissions-records-surges-california-and-underrepresented  
[37] UC press: Admits record number of CA residents and largest class: https://www.universityofcalifornia.edu/press-room/university-california-admits-record-number-california-residents-and-largest-class  
[38] Yale reinstates standardized testing requirement (Reuters): https://www.reuters.com/world/us/yale-university-reinstates-standardized-test-requirement-2024-02-22/  
[39] Georgia Student Finance Commission—Scholarship programs: https://gsfc.georgia.gov/about-gsfc/georgias-scholarship-grant-and-loan-programs  
[40] Georgia Southern—HOPE/Zell Miller scholarship details: https://www.georgiasouthern.edu/admissions-aid/tuition-and-scholarships/types-of-aid/hope-zell-miller-scholarship  
[41] New Hampshire DOE—PACE: https://www.education.nh.gov/who-we-are/division-of-learner-support/bureau-of-instructional-support/performance-assessment-competency-education  
[42] NH DOE—PACE approved under IADA: https://www.education.nh.gov/news/pace-assessment-approved-feds  
[43] EPAA—Three-year impacts of NH PACE: https://epaa.asu.edu/index.php/epaa/article/view/4014  
[44] Applied Measurement in Education—Five-year PACE outcomes: https://www.tandfonline.com/doi/abs/10.1080/08957347.2023.2201700  
[45] IES/NCEE—Evaluation of Title I State Assessment Pilots (IADA): https://ies.ed.gov/ncee/pubs/2023004/pdf/2023004.pdf  
[46] New York Performance Standards Consortium—How it works: https://www.performanceassessment.org/howitworks  
[47] Assessing College Readiness Through Authentic Student Work (Learning Policy Institute): https://learningpolicyinstitute.org/product/assessing-college-readiness-authentic-student-work-report  
[48] MCIEA—Overview: https://www.mciea.org/  
[49] MCIEA—Performance Assessment Institute: https://www.mciea.org/institute  
[50] MCIEA—School Quality Measures research: https://www.mciea.org/school-quality-measures-research  
[51] Vermont Portfolio Assessment—RAND reprint: https://www.rand.org/pubs/reprints/RP366.html  
[52] Vermont Portfolios Reliability—RAND DRU159: https://www.rand.org/pubs/drafts/DRU159.html  
[53] Rhode Island DOE—Proficiency-Based Learning and Graduation (PBGR): https://ride.ri.gov/students-families/education-programs/proficiency-based-learning  
[54] Envision Schools—Our approach: https://envisionschools.org/our-approach/  
[55] Envision Schools—Defense Design Studios (PD): https://envisionschools.org/defense-design-studios/  
[56] AIR—Study of Deeper Learning Opportunities and Outcomes: https://www.air.org/project/study-deeper-learning-opportunities-and-outcomes  
[57] AIR—Persistent graduation advantage for deeper learning network students: https://www.air.org/news/press-release/air-study-finds-persistent-graduation-advantage-students-deeper-learning-network  
[58] IB Diploma Programme—Understanding assessment: https://www.ibo.org/en/programmes/diploma-programme/assessment-and-exams/understanding-ib-assessment/  
[59] IB—Extended Essay overview: https://www.ibo.org/programmes/diploma-programme/curriculum/dp-core/extended-essay/what-is-the-extended-essay/  
[60] IB—U.S. postsecondary outcomes research (DP): https://www.ibo.org/research/outcomes-research/diploma-studies/us-postsecondary-outcomes/  
[61] Pennsylvania PDE—Project Based Assessment portal: https://www.pba.pdesas.org/assessment/assessment/projectbasedassessment/  
[62] Pennsylvania DOE—Keystone Exams overview: https://www.education.pa.gov/K-12/Assessment%20and%20Accountability/Keystones/Pages/default.aspx